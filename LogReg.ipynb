{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b780b34-8386-4749-9251-5081773fec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import os\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554de671-0cc6-4ae1-acc4-015f50dade93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_filename = 'songs_dataset_train.pkl'\n",
    "with open(pickle_filename, 'rb') as file:\n",
    "    train_df = pickle.load(file)\n",
    "\n",
    "\n",
    "pickle_filename = 'songs_dataset_test.pkl'\n",
    "with open(pickle_filename, 'rb') as file:\n",
    "    test_df = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "num_train = train_df.drop(['Lyrics', 'Title', 'Raw_Lyrics'], axis=1)\n",
    "num_test = test_df.drop(['Lyrics', 'Title', 'Raw_Lyrics'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb651403-a86e-401f-a177-76352a2b4280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sets_func(nsets):\n",
    "    \"\"\"\n",
    "    Create 'nsets' random artist sets with corresponding weights.\n",
    "\n",
    "    Args:\n",
    "        nsets (int): The number of sets to generate.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following elements:\n",
    "            - artists_set (list): A list of 'nsets' random artist sets.\n",
    "            - pos_w (float): The positive weight for each set (1 - 1/nsets).\n",
    "            - neg_w (float): The negative weight for each set (1/nsets).\n",
    "    \"\"\"\n",
    "    artists_set = random.sample(list(arts_dict_op.keys()), nsets)\n",
    "    pos_w = (nsets - 1) / nsets\n",
    "    neg_w = 1 / nsets\n",
    "    \n",
    "    return artists_set, pos_w, neg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905c689-7cd9-4993-8a79-8c261e0a56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_sets_func_mine(df, art_set):\n",
    "    \"\"\"\n",
    "    Filter and preprocess a DataFrame based on a given artist set.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame containing artist-related data.\n",
    "        art_set (list): A list of artists to filter the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following elements:\n",
    "            - df2 (DataFrame): The filtered DataFrame with specified columns.\n",
    "            - fts (Index): The column names of the filtered DataFrame.\n",
    "            - pos_w (float): The positive weight for each artist set (1 - 1/n_art).\n",
    "            - neg_w (float): The negative weight for each artist set (1/n_art).\n",
    "    \"\"\"\n",
    "    df2 = df.drop(df.columns[[0, 3, 4]], axis=1)\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "    df2 = df2[df2['Artist'].isin(art_set)]\n",
    "    n_art = len(art_set)\n",
    "    pos_w = (n_art - 1) / n_art\n",
    "    neg_w = 1 / n_art\n",
    "    fts = df2.columns\n",
    "    \n",
    "    return df2, fts, pos_w, neg_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56aa7e2-6da5-429c-949f-82c62bcb1455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_of_arrays(matrix):\n",
    "    \"\"\"\n",
    "    Calculate the mean values along each column of a matrix.\n",
    "\n",
    "    Args:\n",
    "        matrix (numpy.ndarray): The input matrix for which to calculate means.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of mean values for each column of the input matrix.\n",
    "    \"\"\"\n",
    "    mean_values = np.mean(matrix, axis=0)\n",
    "    return mean_values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058b0ba-f331-4617-bc83-5603ee2b5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_df(artist, df):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of features for songs by a specific artist in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        artist (str): The name or identifier of the artist.\n",
    "        df (DataFrame): The input DataFrame containing song data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following elements:\n",
    "            - artist_stats (DataFrame): A DataFrame with the average and standard deviation of features for the artist's songs.\n",
    "            - mean_vector (numpy.ndarray): The mean TF-IDF vector of the artist's songs.\n",
    "    \"\"\"\n",
    "    art_data = df[df['Artist'] == artist]\n",
    "    arrays = art_data['TFIDF_Vector'].values\n",
    "    matrix = np.stack(arrays)\n",
    "    mean_vector = np.array(np.mean(matrix, axis=0))\n",
    "    average_features_artist = art_data.mean(numeric_only=True)\n",
    "    std_features_artist = art_data.std(numeric_only=True)\n",
    "    artist_stats = pd.DataFrame({'Average': average_features_artist, 'Standard Deviation': std_features_artist})\n",
    "    artist_stats = artist_stats.transpose().drop(\"Artist\", axis=1)\n",
    "    \n",
    "    return artist_stats, mean_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cbb061-6b65-4fd1-880a-d1315b43718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_angle(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two vectors.\n",
    "\n",
    "    Args:\n",
    "        vector1 (numpy.ndarray): The first vector.\n",
    "        vector2 (numpy.ndarray): The second vector.\n",
    "\n",
    "    Returns:\n",
    "        float: A similarity score between 0 and 1, where 1 indicates high similarity.\n",
    "        \n",
    "    Note:\n",
    "        This function is typically used for calculating the cosine similarity\n",
    "        between TF-IDF vectors or other vectors in the context of text analysis\n",
    "        or recommendation systems.\n",
    "    \"\"\"\n",
    "    dot_prod = np.dot(vector1, vector2)\n",
    "    mag1 = np.linalg.norm(vector1)\n",
    "    mag2 = np.linalg.norm(vector2)\n",
    "    if mag1 * mag2 != 0:\n",
    "        return dot_prod / (mag1 * mag2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c3686f-cae3-47b2-b3f8-9a407003095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_rows(df):\n",
    "    \"\"\"\n",
    "    Takes a dataframe with the first 2 rows belonging to an artist and the following rows representing songs.\n",
    "    Returns the dataframe to be trained for that artist.\n",
    "    \"\"\"\n",
    "    art_pca = df.iloc[0, -1]\n",
    "\n",
    "    for i in range(2, len(df)):\n",
    "        df.iloc[i, -1] = cosine_angle(art_pca, df.iloc[i, -1])\n",
    "\n",
    "    first_row = df.iloc[0, :-1]\n",
    "    s_row = df.iloc[1, :-1]\n",
    "\n",
    "    mask = s_row != 0  # Create a mask to avoid division by zero\n",
    "    # Convert the values to float64 before assigning them to the DataFrame\n",
    "    df.iloc[2:, :-1] = (first_row - df.iloc[2:, :-1]) / np.where(mask, s_row, 1)\n",
    "    df = df.iloc[2:].reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4214b1-1702-4201-a458-e3c98b89871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Will make the dataframe of songs for any artist\n",
    "def df_maker(artist, df, df2):\n",
    "    \"\"\" \n",
    "    INPUTS\n",
    "    artist- aritst number, int\n",
    "    df- dataframe with songs and their features\n",
    "    output- dataframe with featurs of the song wrt the aritst\n",
    "    \"\"\"\n",
    "    art_df, meanpca = artist_df(artist, df2)\n",
    "    art_df[\"TFIDF_Vector\"] = [meanpca, None]\n",
    "    comb_df = pd.concat([art_df, df])\n",
    "    return (std_rows(comb_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d6bf7-fe99-43ee-882e-504e486f641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_K_accs(y_test, arr):\n",
    "    \"\"\"\n",
    "    Calculate the top-K accuracy scores for a list of predicted indices.\n",
    "\n",
    "    Args:\n",
    "        y_test (list or numpy.ndarray): The true labels or ground truth.\n",
    "        arr (list of lists): A list of lists, where each sublist contains the top-K predicted indices.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of top-K accuracy scores, one for each sublist in 'arr'.\n",
    "\n",
    "    Note:\n",
    "        Top-K accuracy measures the percentage of correctly predicted labels\n",
    "        when considering the top-K predicted labels for each sample. It is useful\n",
    "        for evaluating classification models that provide multiple predictions\n",
    "        for each sample.\n",
    "    \"\"\"\n",
    "    y_test = np.array(y_test)\n",
    "    l = len(y_test)\n",
    "    top_accs = []\n",
    "    \n",
    "    for max_indices in arr:\n",
    "        s = 0\n",
    "        for i in range(0, l):\n",
    "            if y_test[i] in max_indices[i]:\n",
    "                s += 1\n",
    "        top_accs.append(100 * s / l)\n",
    "    \n",
    "    return top_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88bed95-4bfe-4f4e-8830-3ccf3bc2f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_test(artists_set, top, x_train, x_test):\n",
    "    \"\"\"\n",
    "    Perform logistic regression-based artist classification and evaluate top-K accuracy.\n",
    "\n",
    "    Args:\n",
    "        artists_set (list): List of artists to classify.\n",
    "        top (list): List of integers specifying the top-K values for accuracy evaluation.\n",
    "        x_train (DataFrame): Training feature data.\n",
    "        x_test (DataFrame): Testing feature data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following elements:\n",
    "            - probs_by_tops (list of lists): List of top-K predicted artists for each sample.\n",
    "            - top_K_accuracy (list): List of top-K accuracy scores for each top-K value in 'top'.\n",
    "            - coefficients (numpy.ndarray): Mean coefficients from logistic regression models.\n",
    "            - y_test (numpy.ndarray): True labels from the testing data.\n",
    "            - fts (Index): Feature column names.\n",
    "            - artists_set (list): List of artists used in the classification.\n",
    "\n",
    "    Note:\n",
    "        This function performs logistic regression-based artist classification for a given\n",
    "        set of artists and evaluates the top-K accuracy of the predictions. It also returns\n",
    "        the mean coefficients, true labels, feature column names, and the artists in the set.\n",
    "    \"\"\"\n",
    "    # Filter the training data for the specified artist set\n",
    "    df2, _, pos_w, neg_w = n_sets_func_mine(df=x_train, art_set=artists_set)\n",
    "    x_train = df2.drop('Artist', axis=1)\n",
    "    y_train = df2['Artist']\n",
    "\n",
    "    # Filter the testing data for the specified artist set\n",
    "    df3, _, pos_w, neg_w = n_sets_func_mine(df=x_test, art_set=artists_set)\n",
    "    x_test = df3.drop('Artist', axis=1)\n",
    "    y_test = df3['Artist']\n",
    "    fts = x_train.columns\n",
    "\n",
    "    probs = []\n",
    "    coeffs = []\n",
    "\n",
    "    for i in artists_set:\n",
    "        X2 = df_maker(artist=i, df=x_train, df2=df2)\n",
    "        X2 = pd.concat([X2.reset_index(drop=True), x_train.iloc[:, :-1].reset_index(drop=True)], axis=1)\n",
    "        X3 = df_maker(artist=i, df=x_test, df2=df2)\n",
    "        X3 = pd.concat([X3.reset_index(drop=True), x_test.iloc[:, :-1].reset_index(drop=True)], axis=1)\n",
    "        y2 = np.array([1 if x == i else 0 for x in y_train])\n",
    "\n",
    "        # Fit logistic regression model\n",
    "        logreg = LogisticRegression(max_iter=5000, solver='lbfgs', class_weight={0: neg_w, 1: pos_w})\n",
    "        logreg.fit(X2, y2)\n",
    "        coefficients = logreg.coef_\n",
    "        coeffs.append(coefficients[0])\n",
    "        probs.append(logreg.predict_proba(X3)[:, 1])\n",
    "\n",
    "    coeffs = np.vstack(coeffs)\n",
    "    coeffs = np.mean(coeffs, axis=0)\n",
    "    probs = np.array(probs)\n",
    "    probs_by_tops = []\n",
    "\n",
    "    for i in top:\n",
    "        Q = (np.argsort(probs, axis=0)[-i:, :]).transpose()\n",
    "        temp = []\n",
    "        for i in Q:\n",
    "            temp2 = []\n",
    "            for j in i:\n",
    "                temp2.append(artists_set[j])\n",
    "            temp.append(temp2)\n",
    "        probs_by_tops.append(temp)\n",
    "\n",
    "    return probs_by_tops, top_K_accs(y_test=y_test, arr=probs_by_tops), coeffs, y_test, fts, artists_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bda8de-8233-4697-ae07-74ed979089f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_train_acc(artists_set, top, x_train):\n",
    "    \"\"\"\n",
    "    Calculate top-K accuracy for logistic regression training on a given artist set.\n",
    "\n",
    "    Args:\n",
    "        artists_set (list): List of artists for training.\n",
    "        top (list): List of integers specifying the top-K values for accuracy evaluation.\n",
    "        x_train (DataFrame): Training feature data.\n",
    "\n",
    "    Returns:\n",
    "        list: List of top-K accuracy scores for each top-K value in 'top'.\n",
    "\n",
    "    Note:\n",
    "        This function performs logistic regression-based training for a given\n",
    "        set of artists and evaluates the top-K accuracy of the training predictions.\n",
    "    \"\"\"\n",
    "    # Filter the training data for the specified artist set\n",
    "    df2, _, pos_w, neg_w = n_sets_func_mine(df=x_train, art_set=artists_set)\n",
    "    x_train = df2.drop('Artist', axis=1)\n",
    "    y_train = df2['Artist']\n",
    "\n",
    "    probs = []\n",
    "\n",
    "    for i in artists_set:\n",
    "        X2 = df_maker(artist=i, df=x_train, df2=df2)\n",
    "        X2 = pd.concat([X2.reset_index(drop=True), x_train.iloc[:, :-1].reset_index(drop=True)], axis=1)\n",
    "        y2 = np.array([1 if x == i else 0 for x in y_train])\n",
    "\n",
    "        # Fit logistic regression model\n",
    "        logreg = LogisticRegression(max_iter=5000, solver='lbfgs', class_weight={0: neg_w, 1: pos_w})\n",
    "        logreg.fit(X2, y2)\n",
    "        probs.append(logreg.predict_proba(X2)[:, 1])\n",
    "\n",
    "    probs = np.array(probs)\n",
    "    probs_by_tops = []\n",
    "\n",
    "    for i in top:\n",
    "        Q = (np.argsort(probs, axis=0)[-i:, :]).transpose()\n",
    "        temp = []\n",
    "        for i in Q:\n",
    "            temp2 = []\n",
    "            for j in i:\n",
    "                temp2.append(artists_set[j])\n",
    "            temp.append(temp2)\n",
    "        probs_by_tops.append(temp)\n",
    "\n",
    "    return top_K_accs(y_test=y_train, arr=probs_by_tops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0673b77-3a38-4d08-b211-53d5e730d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_test_random_bagging(artists_set, top, x_train, x_test, nest, max_sam, max_fts, oob, warm):\n",
    "    \"\"\"\n",
    "    Perform logistic regression-based artist classification with bagging and evaluate top-K accuracy.\n",
    "\n",
    "    Args:\n",
    "        artists_set (list): List of artists to classify.\n",
    "        top (list): List of integers specifying the top-K values for accuracy evaluation.\n",
    "        x_train (DataFrame): Training feature data.\n",
    "        x_test (DataFrame): Testing feature data.\n",
    "        nest (int): Number of base estimators in the bagging ensemble.\n",
    "        max_sam (float or int): The number of samples to draw from X2 to train each base estimator.\n",
    "        max_fts (float or int): The number of features to draw from X2 to train each base estimator.\n",
    "        oob (bool): Whether to use out-of-bag samples to estimate the generalization error.\n",
    "        warm (bool): Whether to reuse the solution of the previous call to fit and add more estimators to the ensemble.\n",
    "\n",
    "    Returns:\n",
    "        list: List of top-K accuracy scores for each top-K value in 'top'.\n",
    "\n",
    "    Note:\n",
    "        This function performs logistic regression-based artist classification with bagging\n",
    "        for a given set of artists and evaluates the top-K accuracy of the predictions.\n",
    "    \"\"\"\n",
    "    # Filter the training data for the specified artist set\n",
    "    df2, _, pos_w, neg_w = n_sets_func_mine(df=x_train, art_set=artists_set)\n",
    "    x_train = df2.drop('Artist', axis=1)\n",
    "    y_train = df2['Artist']\n",
    "\n",
    "    # Filter the testing data for the specified artist set\n",
    "    df3, _, pos_w, neg_w = n_sets_func_mine(df=x_test, art_set=artists_set)\n",
    "    x_test = df3.drop('Artist', axis=1)\n",
    "    y_test = df3['Artist']\n",
    "    fts = x_train.columns\n",
    "    \n",
    "    probs = []\n",
    "\n",
    "    for i in artists_set:\n",
    "        X2 = df_maker(artist=i, df=x_train, df2=df2)\n",
    "        X2 = pd.concat([X2.reset_index(drop=True), x_train.iloc[:, :-1].reset_index(drop=True)], axis=1)\n",
    "        X3 = df_maker(artist=i, df=x_test, df2=df2)\n",
    "        X3 = pd.concat([X3.reset_index(drop=True), x_test.iloc[:, :-1].reset_index(drop=True)], axis=1)\n",
    "        y2 = np.array([1 if x == i else 0 for x in y_train])\n",
    "\n",
    "        # Fit logistic regression model with bagging\n",
    "        logreg = LogisticRegression(max_iter=8000, solver='lbfgs', class_weight={0: neg_w, 1: pos_w})\n",
    "        logreg_bagging = BaggingClassifier(estimator=logreg, n_estimators=nest, max_samples=max_sam, max_features=max_fts, oob_score=oob, warm_start=warm)\n",
    "        logreg_bagging.fit(X2, y2)\n",
    "        probs.append(logreg_bagging.predict_proba(X3)[:, 1])\n",
    "\n",
    "    probs = np.array(probs)\n",
    "    probs_by_tops = []\n",
    "\n",
    "    for i in top:\n",
    "        Q = (np.argsort(probs, axis=0)[-i:, :]).transpose()\n",
    "        temp = []\n",
    "        for i in Q:\n",
    "            temp2 = []\n",
    "            for j in i:\n",
    "                temp2.append(artists_set[j])\n",
    "            temp.append(temp2)\n",
    "        probs_by_tops.append(temp)\n",
    "\n",
    "    return top_K_accs(y_test=y_test, arr=probs_by_tops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c039aaf-6a9a-4e64-b787-ae6bb1899bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_test_random_boosting(artists_set, top, x_train, x_test):\n",
    "    \"\"\"\n",
    "    Perform logistic regression-based artist classification with AdaBoost and evaluate top-K accuracy.\n",
    "\n",
    "    Args:\n",
    "        artists_set (list): List of artists to classify.\n",
    "        top (list): List of integers specifying the top-K values for accuracy evaluation.\n",
    "        x_train (DataFrame): Training feature data.\n",
    "        x_test (DataFrame): Testing feature data.\n",
    "\n",
    "    Returns:\n",
    "        list: List of top-K accuracy scores for each top-K value in 'top'.\n",
    "\n",
    "    Note:\n",
    "        This function performs logistic regression-based artist classification with AdaBoost\n",
    "        for a given set of artists and evaluates the top-K accuracy of the predictions.\n",
    "    \"\"\"\n",
    "    # Filter the training data for the specified artist set\n",
    "    df2, _, pos_w, neg_w = n_sets_func_mine(df=x_train, art_set=artists_set)\n",
    "    x_train = df2.drop('Artist', axis=1)\n",
    "    y_train = df2['Artist']\n",
    "\n",
    "    # Filter the testing data for the specified artist set\n",
    "    df3, _, pos_w, neg_w = n_sets_func_mine(df=x_test, art_set=artists_set)\n",
    "    x_test = df3.drop('Artist', axis=1)\n",
    "    y_test = df3['Artist']\n",
    "    \n",
    "    probs = []\n",
    "\n",
    "    for i in artists_set:\n",
    "        X2 = df_maker(artist=i, df=x_train, df2=df2)\n",
    "        X2 = pd.concat([X2.reset_index(drop=True), x_train.iloc[:, :-1].reset_index(drop=True)], axis=1)\n",
    "        X3 = df_maker(artist=i, df=x_test, df2=df2)\n",
    "        X3 = pd.concat([X3.reset_index(drop=True), x_test.iloc[:, :-1].reset_index(drop=True)], axis=1)\n",
    "        y2 = np.array([1 if x == i else 0 for x in y_train])\n",
    "\n",
    "        # Fit logistic regression model with AdaBoost\n",
    "        adaboost = AdaBoostClassifier(estimator=LogisticRegression(max_iter=5000), n_estimators=50, learning_rate=1)\n",
    "        adaboost.fit(X2, y2)\n",
    "        probs.append(adaboost.predict_proba(X3)[:, 1])\n",
    "\n",
    "    probs = np.array(probs)\n",
    "    probs_by_tops = []\n",
    "\n",
    "    for i in top:\n",
    "        Q = (np.argsort(probs, axis=0)[-i:, :]).transpose()\n",
    "        temp = []\n",
    "        for i in Q:\n",
    "            temp2 = []\n",
    "            for j in i:\n",
    "                temp2.append(artists_set[j])\n",
    "            temp.append(temp2)\n",
    "        probs_by_tops.append(temp)\n",
    "\n",
    "    return top_K_accs(y_test=y_test, arr=probs_by_tops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394a819-b8c9-4538-a0a1-bd708137a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassy(n, k, l):\n",
    "    \n",
    "    # n : number of artists considered\n",
    "    # k : top k predictions considered\n",
    "    # l : top l misclassified\n",
    "\n",
    "    #Returns:\n",
    "    #list: the top l most misclassified artist numbers by percentage.\n",
    "    #list: the top l least misclassified artist numbers by percentage.\n",
    "    \n",
    "    misclassified_numbers = Counter()\n",
    "    artists_set = random.sample(list(arts_dict_op.keys()), n)\n",
    "    probs_by_tops, accs, _, y_test, _, artists_set = logistic_test(artists_set, top = [k], x_train = num_train,x_test= num_test)\n",
    "\n",
    "    probs_by_tops = probs_by_tops[0]\n",
    "    for i, true_value in enumerate(y_test):\n",
    "        if true_value not in probs_by_tops[i]:\n",
    "            misclassified_numbers[true_value] += 1\n",
    "\n",
    "    total_samples = Counter(y_test)  # Count occurrences of each number in y_test\n",
    "\n",
    "    misclassification_percentages = {\n",
    "        number: count / total_samples[number] * 100\n",
    "        for number, count in misclassified_numbers.items()\n",
    "    }\n",
    "\n",
    "    least_misclassified = sorted(\n",
    "        misclassification_percentages.items(), key=lambda x: x[1]\n",
    "    )[:l]\n",
    "    \n",
    "    top_misclassified = sorted(\n",
    "        misclassification_percentages.items(), key=lambda x: x[1], reverse=True\n",
    "    )[:l]\n",
    "\n",
    "    print(f\"The top {l} most misclassified numbers by percentage are:\\n\")\n",
    "    for number, percentage in top_misclassified:\n",
    "        print(f\"Number: {arts_dict_op[number]}, Misclassification percentage: {percentage:.2f}%\")\n",
    "        \n",
    "    print(f\"The top {l} least misclassified numbers by percentage are:\\n\")\n",
    "    for number, percentage in least_misclassified:\n",
    "        print(f\"Number: {arts_dict_op[number]}, Misclassification percentage: {percentage:.2f}%\")\n",
    "        \n",
    "    return [top[0] for top in top_misclassified], [top[0] for top in least_misclassified]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d1e3a-c7fb-445d-88fa-f240daa37e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_misclassified_top_n(y_test, probs, n):\n",
    "    \"\"\"\n",
    "    Get the top N most frequently misclassified values along with their counts.\n",
    "\n",
    "    Args:\n",
    "        y_test (list or numpy.ndarray): True labels.\n",
    "        probs (list or numpy.ndarray): Predicted probabilities.\n",
    "        n (int): Number of top misclassified values to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains a misclassified value and its count.\n",
    "\n",
    "    Note:\n",
    "        This function takes true labels and predicted probabilities, identifies misclassified values\n",
    "        by comparing them, counts the occurrences of each misclassified value, and returns the top N\n",
    "        misclassified values with the highest counts.\n",
    "    \"\"\"\n",
    "    misclassified = []\n",
    "    \n",
    "    # Iterate over the predictions and true values\n",
    "    for true_val, pred_val in zip(y_test, probs):\n",
    "        if true_val != pred_val:\n",
    "            misclassified.append(pred_val)\n",
    "    \n",
    "    # Count the occurrences of misclassified values\n",
    "    vote_counts = Counter(misclassified)\n",
    "    \n",
    "    # Get the top N misclassified values with the most votes\n",
    "    top_n_misclassified = vote_counts.most_common(n)\n",
    "    \n",
    "    return top_n_misclassified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651896e2-0f7b-4d2e-8370-d5fed937a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_tog(brr, nlist, top, save_dir):\n",
    "    \"\"\"\n",
    "    Plot multiple arrays of y values with respect to x values and save the plot.\n",
    "\n",
    "    Args:\n",
    "        brr (list of lists): List of lists of y values for each line on the plot.\n",
    "        nlist (list): List of x values corresponding to the y values.\n",
    "        top (list): List of top-K values for labeling the lines.\n",
    "        save_dir (str): Directory where the plot will be saved.\n",
    "\n",
    "    Note:\n",
    "        This function takes a list of lists of y values ('brr'), a list of x values ('nlist'),\n",
    "        a list of top-K values ('top'), and a directory path ('save_dir'). It plots each list\n",
    "        of y values with respect to x values, labels the lines with top-K values, and saves the\n",
    "        plot in the specified directory.\n",
    "    \"\"\"\n",
    "    brr2 = brr\n",
    "\n",
    "    max_len = max(len(sublist) for sublist in brr2)\n",
    "    drr = [[] for _ in range(max_len)]\n",
    "\n",
    "    for sublist in brr2:\n",
    "        for i, element in enumerate(sublist):\n",
    "            drr[i].append(element)\n",
    "\n",
    "    brr2 = drr\n",
    "\n",
    "    counter = 0\n",
    "    for y_values in brr2:\n",
    "        plt.plot(nlist[-len(y_values):], y_values, marker='o', label=\"top \" + str(top[counter]) + \" choices\")\n",
    "        counter += 1\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Number of artists')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy of n artists with top k choices')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "    save_path = os.path.join(save_dir, f'top_k_together_test.png')\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151bd20c-4ba4-45af-abd1-9f04643d0ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, st, name):\n",
    "    \"\"\"\n",
    "    Process feature data by aggregating coefficients for features with the same prefix.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): Input data containing 'feature' and 'name' columns.\n",
    "        st (str): Prefix of features to be aggregated.\n",
    "        name (str): Name of the coefficient column.\n",
    "\n",
    "    Returns:\n",
    "        dict: Processed data as a dictionary containing 'feature' and 'name' columns.\n",
    "\n",
    "    Note:\n",
    "        This function takes a DataFrame 'data' with 'feature' and 'name' columns. It aggregates\n",
    "        coefficients for features that start with the specified prefix 'st' and returns the\n",
    "        processed data as a dictionary with 'feature' and 'name' columns.\n",
    "    \"\"\"\n",
    "    features = data['feature']\n",
    "    coefficients = data[name]\n",
    "    \n",
    "    new_features = []\n",
    "    new_coefficients = []\n",
    "    pos_coefficients = []\n",
    "    pos_total = 0.0\n",
    "    \n",
    "    for feature, coefficient in zip(features, coefficients):\n",
    "        if feature.startswith(st):\n",
    "            pos_coefficients.append(coefficient)\n",
    "        else:\n",
    "            new_features.append(feature)\n",
    "            new_coefficients.append(coefficient)\n",
    "    \n",
    "    if pos_coefficients:\n",
    "        pos_total = sum(pos_coefficients)\n",
    "        real = st\n",
    "        if(st == 'PC' or st =='TF'):\n",
    "            real = \"TF IDF Feat\"\n",
    "        elif(st=='Nb'):\n",
    "            real = \"shape Feat\"\n",
    "        elif(st == 'RI'):\n",
    "            real = 'RID Feat'\n",
    "        elif(st == 'PO'):\n",
    "            real = 'POS Feat'\n",
    "        elif(st==\"Su\"):\n",
    "            real= 'Subjectivity'\n",
    "        elif(st == 'Po'):\n",
    "            real = 'Polarity'\n",
    "        elif(st=='TT'):\n",
    "            real = 'TTR'\n",
    "        elif(st == 'Sl'):\n",
    "            real = 'Slang'\n",
    "        elif(st=='Ra'):\n",
    "            real = \"Rare\"\n",
    "        elif(st=='Li'):\n",
    "            real = \"Line similarity\"\n",
    "        elif(st==\"CH\"):\n",
    "            real = 'Chunk Feat'\n",
    "        elif(st=='Ti'):\n",
    "            real = 'Title in Song'\n",
    "        new_features.append(real)\n",
    "        new_coefficients.append(pos_total)\n",
    "    \n",
    "    processed_data = {\n",
    "        'feature': new_features,\n",
    "        name: new_coefficients\n",
    "    }\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23676f8a-3763-431d-bc28-a6a82abd794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(data, name, b, c):\n",
    "    \"\"\"\n",
    "    Create and display a bar plot of feature importances or coefficients.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Dictionary containing feature names and corresponding values.\n",
    "        name (str): Name of the values to be plotted.\n",
    "        b (bool): Whether to adjust figure size and label fonts.\n",
    "        c (int): Plot type indicator (1 for coefficients, 2 for normalized importance, 3 for importance percentage).\n",
    "\n",
    "    Note:\n",
    "        This function takes a dictionary 'data' with feature names as keys and corresponding values,\n",
    "        'name' as the name of the values to be plotted, 'b' as a boolean to adjust figure size and label fonts,\n",
    "        and 'c' as an indicator for the type of plot. It creates and displays a bar plot of feature importances\n",
    "        or coefficients. The plot can be saved as 'ft_importance_test.png' in the current working directory.\n",
    "    \"\"\"\n",
    "    feature_importance_df = pd.DataFrame(data)\n",
    "    sorted_df = feature_importance_df.sort_values(name)\n",
    "    if b:\n",
    "        plt.figure(figsize=(12, 6))  # Set the figure size to be wider (12 units wide, 6 units tall)\n",
    "        x_label_fontsize = 8  # Set the font size for x-axis labels\n",
    "    else:\n",
    "        plt.figure()  # Use default figure size\n",
    "        x_label_fontsize = 12  # Set the font size for x-axis labels\n",
    "    \n",
    "    plt.bar(sorted_df['feature'], sorted_df[name], facecolor='gray', align='center')\n",
    "    plt.xlabel('Feature', fontsize=x_label_fontsize)  # Set the x-axis label font size\n",
    "    plt.ylabel(name)  # Reduce the y-axis label size\n",
    "    if(c==3):\n",
    "        plt.title(f'Importance Percentage in the classification of the features')  # Reduce the title size\n",
    "    if(c==2):\n",
    "        plt.title(f'Importance in the classification of the features (absolute value normalised)')\n",
    "    if(c==1):\n",
    "        plt.title(f'Coefficients in the classification of the features')\n",
    "    plt.xticks(rotation=60, ha='right', fontsize=8)  \n",
    "    plt.yticks(fontsize=8)  \n",
    "    plt.show()\n",
    "    save_dir = os.getcwd()  \n",
    "    save_path = os.path.join(save_dir, 'ft_importance_test.png')\n",
    "    plt.savefig(save_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4278c-d89b-45c4-bfd4-e9f71626a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_imp1(crr, fts):\n",
    "    \"\"\"\n",
    "    Plot feature importances based on coefficients (absolute value thresholded).\n",
    "\n",
    "    Args:\n",
    "        crr (list of lists): List of lists of coefficients for different models or iterations.\n",
    "        fts (list): List of feature names.\n",
    "\n",
    "    Note:\n",
    "        This function takes a list of lists 'crr' containing coefficients for different models or iterations,\n",
    "        and a list of feature names 'fts'. It plots feature importances based on coefficients with an absolute\n",
    "        value threshold of 0.05 using the 'plotter' function.\n",
    "    \"\"\"\n",
    "    for coeffs in crr:\n",
    "        fts2 = [(element + \"_DN\") for element in fts if element != 'Artist']\n",
    "        for i in range(0, len(fts2)):\n",
    "            if (fts2[i] == \"PCA diff normal\"):\n",
    "                fts2[i] = \"TF_IDF vector similarity\"\n",
    "        fts3 = [element for element in fts if element != 'Artist' and element != 'PCA']\n",
    "        fts2 += fts3\n",
    "        fts4 = []\n",
    "        coeffs2 = []\n",
    "        for i in range(0, len(coeffs)):\n",
    "            if (np.abs(coeffs[i]) >= 0.05):\n",
    "                coeffs2.append(coeffs[i])\n",
    "                fts4.append(fts2[i])\n",
    "        data = {'feature': fts4, 'coefficient': coeffs2}\n",
    "        plotter(data, 'coefficient', True, 1)\n",
    "\n",
    "def feature_imp2(crr, fts):\n",
    "    \"\"\"\n",
    "    Plot feature importances based on normalized absolute coefficients (without lyric features).\n",
    "\n",
    "    Args:\n",
    "        crr (list of lists): List of lists of coefficients for different models or iterations.\n",
    "        fts (list): List of feature names.\n",
    "\n",
    "    Note:\n",
    "        This function takes a list of lists 'crr' containing coefficients for different models or iterations,\n",
    "        and a list of feature names 'fts'. It plots feature importances based on normalized absolute coefficients\n",
    "        without considering features starting with 'Ly' using the 'plotter' function.\n",
    "    \"\"\"\n",
    "    for coeffs in crr:\n",
    "        fts2 = [(element + \" diff normal\") for element in fts if element != 'Artist']\n",
    "        fts3 = [element for element in fts if element != 'Artist' and element != 'PCA']\n",
    "        fts2 += fts3\n",
    "        coeffs2 = np.absolute(coeffs)\n",
    "        coeffs2 = coeffs2 / np.linalg.norm(coeffs2)\n",
    "        indices = []\n",
    "        for i in range(0, len(fts2)):\n",
    "            if (fts2[i].startswith('Ly')):\n",
    "                indices.append(i)\n",
    "        result = [x for i, x in enumerate(fts2) if i not in indices]\n",
    "        res = [x for i, x in enumerate(coeffs2) if i not in indices]\n",
    "        data = {'feature': result, 'coefficient': res}\n",
    "\n",
    "        for bruh in fts3:\n",
    "            data = process_data(data, bruh[:2], 'coefficient')\n",
    "        plotter(data, 'coefficient', False, 2)\n",
    "\n",
    "def feature_imp3(crr, fts):\n",
    "    \"\"\"\n",
    "    Plot feature importances based on percentage of normalized absolute coefficients (without lyric features).\n",
    "\n",
    "    Args:\n",
    "        crr (list of lists): List of lists of coefficients for different models or iterations.\n",
    "        fts (list): List of feature names.\n",
    "\n",
    "    Note:\n",
    "        This function takes a list of lists 'crr' containing coefficients for different models or iterations,\n",
    "        and a list of feature names 'fts'. It plots feature importances based on the percentage of normalized\n",
    "        absolute coefficients without considering features starting with 'Ly' using the 'plotter' function.\n",
    "    \"\"\"\n",
    "    for coeffs in crr:\n",
    "        fts2 = [(element + \" diff normal\") for element in fts if element != 'Artist']\n",
    "        fts3 = [element for element in fts if element != 'Artist' and element != 'PCA']\n",
    "        fts2 += fts3\n",
    "        coeffs2 = np.absolute(coeffs)\n",
    "        coeffs2 = coeffs2 / np.linalg.norm(coeffs2)\n",
    "        coeffs3 = 100 * coeffs2 / np.sum(coeffs2)\n",
    "        indices = []\n",
    "        for i in range(0, len(fts2)):\n",
    "            if (fts2[i].startswith('Ly')):\n",
    "                indices.append(i)\n",
    "        result = [x for i, x in enumerate(fts2) if i not in indices]\n",
    "        res = [x for i, x in enumerate(coeffs3) if i not in indices]\n",
    "        data = {'feature': result, 'Percentage': res}\n",
    "        for bruh in fts3:\n",
    "            if (bruh.startswith('Ly')):\n",
    "                continue\n",
    "            data = process_data(data, bruh[:2], 'Percentage')\n",
    "        plotter(data, 'Percentage', False, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d589b5bd-254a-44d4-bb74-61dc74858919",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist=[128]\n",
    "brr=[]\n",
    "brrlog=[]\n",
    "crr=[]\n",
    "top=[]\n",
    "fts = np.array(new_df.columns)\n",
    "for n in nlist:\n",
    "    maxbr=[0]\n",
    "    maxcr=0\n",
    "    maxbrlog=[0]\n",
    "    top =[2**i for i in range(0, (int)(np.log2(n//2)+1))]\n",
    "    for i in range(0,1):\n",
    "        aset =  random.sample(list(arts_dict_op.keys()), n) \n",
    "        _,br,cr,_,_,_ = logistic_test(artists_set=aset,top=top, x_train = num_train, x_test = num_test)\n",
    "        if(br[0]>maxbr[0]):\n",
    "            maxbr = br\n",
    "            maxcr = cr\n",
    "        a = logistic_test_random_bagging(artists_set=aset, top = top, nest=10, x_train = num_train, x_test = num_test, max_sam = 1.0, max_fts = 1.0, oob = False, warm = True)\n",
    "        print(a)\n",
    "        if(a[0]>maxbrlog[0]):\n",
    "            maxbrlog = a\n",
    "    brr.append(maxbr)\n",
    "    crr.append(maxcr)\n",
    "    brrlog.append(maxbrlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb0186-73c6-4e06-9320-c83bde6f76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE THIS\n",
    "\n",
    "brrsave = brr\n",
    "crrsave = crr\n",
    "brrlogsave = brrlog\n",
    "\n",
    "topsave = [1,2,4,8,16,32]\n",
    "bs2 = brrsave\n",
    "cs2 = crrsave\n",
    "bls2 = brrlogsave\n",
    "ts2 = topsave\n",
    "\n",
    "brrsave = bs2\n",
    "crrsave = cs2\n",
    "brrlogsave = bls2\n",
    "topsave = ts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341c53c-5119-459c-8052-d352706b4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_dict = {}  # Dictionary to store feature families and their variances\n",
    "\n",
    "for feature in numerical_df_scaled.columns:\n",
    "    if feature[:2] in {\"Ar\", \"Mi\"}:\n",
    "        continue\n",
    "    if feature[:2] == \"PO\":\n",
    "        family = \"POS feat\"\n",
    "    elif feature[:2] == \"CH\":\n",
    "        family = \"CHUNK feat\"\n",
    "    elif feature[:2] == \"RI\":\n",
    "        family = \"RID feat\"\n",
    "    else:\n",
    "        family = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c5b14-41f6-4b05-8fc3-621de031f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp1(crrsave, fts)\n",
    "feature_imp2(crrsave, fts)\n",
    "feature_imp3(crrsave, fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37d309-3c17-4881-990f-2fbbca182027",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_tog(brr = brr, nlist =nlist, top = top)\n",
    "plot_top_tog(brr = brrlog, nlist =nlist, top = top)\n",
    "feature_imp1(crr=crr, fts = fts)\n",
    "feature_imp2(crr=crr, fts = fts)\n",
    "feature_imp3(crr=crr, fts = fts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
